{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439740be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "import IPython.display as ipd                               \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15d2cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Konfiguration: Plots \"\"\"\n",
    "sns.set_style(\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2328e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pfad = 'ergebnis/gesamt/'\n",
    "\n",
    "\"\"\"Konfiguration: Daten einlesen\"\"\"\n",
    "\n",
    "standort_listen = {\n",
    "    'A': 'daten/A.csv',\n",
    "    'B': 'daten/B.csv',\n",
    "    'C': 'daten/C.csv',\n",
    "    'D': 'daten/D.csv',\n",
    "    'E': 'daten/E.csv',\n",
    "    'F': 'daten/F.csv'\n",
    "}\n",
    "\n",
    "# Sortierreihenfolge bei Vergleich\n",
    "# d.h.: Originale werden immer aus dem Bestand genommen\n",
    "# der vor einem anderen kommt\n",
    "standorte_nach_prioritaet = [\n",
    "    # Standorte\n",
    "    'A',\n",
    "    'F',\n",
    "    'E',\n",
    "    # Stud.\n",
    "    'B',\n",
    "    'C',\n",
    "    'D'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "interpretiere_als_leer = [\n",
    "    '0\\'00000\"',\n",
    "    '',\n",
    "    'UNBEKANNT',\n",
    "    'Unbekannt',\n",
    "    '-',\n",
    "    'o. A',\n",
    "    'o.A.',\n",
    "    # BNR: Platzhalter-Werte\n",
    "    '[]',\n",
    "    '[-]', \n",
    "    '[unbekannt]',\n",
    "    '[PROMO]',\n",
    "    '[- PROMO]',\n",
    "    '[[ PROMO]]',\n",
    "    '[ PROMO]',\n",
    "    '[Promo]',\n",
    "    '[Promo-CD]',\n",
    "    '[o. A.]',\n",
    "    '[ohne Nummer]',\n",
    "    '[ohne Nr.]',\n",
    "    '[o. Nr.]'\n",
    "    # RHTI: Leere Werte\n",
    "    ' \"',\n",
    "    ' \" ',\n",
    "    # MIT: Leere Werte\n",
    "    'Diverse',\n",
    "    'Nicht genannt',\n",
    "    'nicht genannt'\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "Sonstige, überdurchschnittlich häufige Werte, ggf. auch als leer interpretieren?\n",
    "    # RHTI: Allweltstitel \n",
    "    'Live',\n",
    "    'Streichquartette',\n",
    "    'Lieder',\n",
    "    'Kammermusik',\n",
    "    'Live USA',\n",
    "    'Greatest hits', \n",
    "    'Greatest Hits',\n",
    "    'Die großen Erfolge',\n",
    "    # MIT: Gruppenbezeichnungen\n",
    "    'Diverse',\n",
    "    'Ensemble',\n",
    "    'Orchester',\n",
    "    'Original Cast'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for wert in list(interpretiere_als_leer):\n",
    "    interpretiere_als_leer.append(wert.lower())\n",
    "    interpretiere_als_leer.append(wert.upper())\n",
    "\n",
    "mapping_spalte_dtype = {\n",
    "         'BEST': 'string',\n",
    "         'ANR': 'string',\n",
    "         'EAN': 'string',\n",
    "         'PEAN': 'string',\n",
    "         'LC': 'string',\n",
    "         'LN': 'string',\n",
    "         'BNR':'string',\n",
    "         'TTS': 'string',\n",
    "         'MIT': 'string',\n",
    "         'MIT_TYP': 'string',\n",
    "         'DAUER': 'string',\n",
    "         'ABS_DAUER': 'string',\n",
    "         'T-ISRC': 'string',\n",
    "         'T-RHTI': 'string',\n",
    "         'RHTI': 'string',\n",
    "         'TRÄGER': 'Int64',\n",
    "         'SEITE': 'Int64',\n",
    "         'TAKE': 'Int64'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beb5c6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Daten einlesen und aufbereiten\"\"\"\n",
    "\n",
    "standort_dataframes = dict()\n",
    "for standort in standort_listen:\n",
    "    standort_liste = standort_listen[standort]\n",
    "    standort_dataframes[standort] = pd.read_csv(standort_listen[standort], sep=';',\n",
    "                                                index_col=1,\n",
    "                                                na_values=interpretiere_als_leer,\n",
    "                                                usecols=lambda x: 'l_' not in x and 'unnamed' not in x.lower(),\n",
    "                                                dtype=mapping_spalte_dtype,\n",
    "                                                encoding='latin1')\n",
    "    \n",
    "    standort_dataframes[standort].index = standort_dataframes[standort].index.astype(str)\n",
    "\n",
    "\n",
    "kb = pd.concat([standort_dataframes[standort] for standort in standort_dataframes])\n",
    "kb['BEST'] = kb['BEST'].astype('category')\n",
    "kb['BEST'].cat.set_categories(standorte_nach_prioritaet, inplace=True)\n",
    "\n",
    "kb = kb[kb['TTS'].str.contains('Compact') == True]\n",
    "\n",
    "kb['EAN/PEAN'] = kb['EAN']\n",
    "del kb['EAN']\n",
    "kb['EAN/PEAN'].fillna(kb['PEAN'], inplace=True)\n",
    "del kb['PEAN']\n",
    "kb['DAUER'].fillna(kb['ABS_DAUER'], inplace=True)\n",
    "del kb['ABS_DAUER']\n",
    "kb['LC'].fillna(kb['LN'], inplace=True)\n",
    "del kb['LN']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef971ae0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"def vereinheitliche(duplicates):\n",
    "    if len(duplicates) > 1:\n",
    "        cols = ['MIT', \n",
    "                'RHTI', \n",
    "                'T-RHTI', \n",
    "                'DAUER', \n",
    "                'EAN/PEAN', \n",
    "                'T-ISRC', \n",
    "                'LC', \n",
    "                'BNR', \n",
    "                'TRÄGER',\n",
    "                'SEITE',\n",
    "                'TAKE']\n",
    "        assign = {col:duplicates.loc[~pd.isnull(duplicates[col])].head(1)[col] for col in cols}\n",
    "        duplicates = duplicates.assign(**assign)\n",
    "    return duplicates\n",
    "\n",
    "kb = kb.groupby(['ANR']).apply(vereinheitliche)\"\"\"\n",
    "kb = kb[~kb.index.duplicated(keep='first')]\n",
    "del kb['MIT_TYP']\n",
    "del kb['TTS']\n",
    "assert kb.index.is_unique == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbc0716",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983d557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for standort in standort_listen:\n",
    "    cols = kb.columns\n",
    "    mit_wert = [ kb.loc[kb['BEST'] == standort, col].count() for col in cols]\n",
    "    ohne_wert = [ kb.loc[kb['BEST'] == standort, col].isnull().sum() for col in cols]\n",
    "    compare_cols = pd.DataFrame({'fehlt': ohne_wert, 'vorhanden': mit_wert}, index=cols)\n",
    "    ax = compare_cols.plot(kind='barh', stacked=True, title=f'{standort}: Fehlende Daten')\n",
    "    ax.set(xlabel='Einheiten', ylabel='Spalten')\n",
    "    plt.title(f'{standort}: Fehlende Werte')\n",
    "    plt.savefig(f'{save_pfad}/img/{standort}_fehlende_werte.svg')\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc8b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116ae052",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Konfiguration: Vergleiche \"\"\"\n",
    "\n",
    "\n",
    "ERLAUBTE_BEDINGUNGEN = [\n",
    "    'schliesse_dubletten_auch_ein_wenn_nicht_mindestabstand',\n",
    "    'traeger_seite_take_fehlen',\n",
    "    'bnr_mindestlaenge',\n",
    "    'bnr_fehlt'\n",
    "]\n",
    "\n",
    "\n",
    "vergleiche = dict()\n",
    "def add_vergleich(name: str,\n",
    "                  nutze_spalten: list,\n",
    "                  **bedingungen) -> None:\n",
    "\n",
    "    #nutze_spalten.sort()\n",
    "    \n",
    "    if name in vergleiche:\n",
    "        raise KeyError(f'Name ({name}) bereits in Vergleich')\n",
    "    \n",
    "    if nutze_spalten in vergleiche.values():\n",
    "        raise ValueError(f'Vergleich ({nutze_spalten}) bereits vorhanden!')\n",
    "        \n",
    "    vergleiche[name] = dict()\n",
    "    \n",
    "    vergleiche[name] = dict()\n",
    "    vergleiche[name]['nutze_spalten'] = nutze_spalten\n",
    "    \n",
    "    for spalte in nutze_spalten:\n",
    "        if spalte not in kb.columns:\n",
    "            raise ValueError(f'Spalte ({spalte}) ist nicht in den Daten.')\n",
    "    if bedingungen is not None:\n",
    "        for bedingung in bedingungen:\n",
    "            if bedingung not in ERLAUBTE_BEDINGUNGEN:\n",
    "                raise ValueError(f'Bedingung ({bedingung}) ist unbekannt.')\n",
    "        vergleiche[name].update(bedingungen)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "# Vergleiche\n",
    "add_vergleich('alles',\n",
    "              ['TRÄGER', 'SEITE', 'TAKE', 'EAN/PEAN', 'LC', 'BNR', 'MIT', 'RHTI', 'T-ISRC', 'T-RHTI'],\n",
    "              schliesse_dubletten_auch_ein_wenn_nicht_mindestabstand=True)\n",
    "\n",
    "add_vergleich('LC, BNR, T-ISRC',\n",
    "              ['LC', 'BNR', 'T-ISRC'],\n",
    "             )\n",
    "\n",
    "add_vergleich('EAN, T-ISRC',\n",
    "              ['EAN/PEAN', 'T-ISRC'],\n",
    "              schliesse_dubletten_auch_ein_wenn_nicht_mindestabstand=True)\n",
    "\n",
    "add_vergleich('RHTI, T-ISRC',\n",
    "              ['RHTI', 'T-ISRC'],\n",
    "              schliesse_dubletten_auch_ein_wenn_nicht_mindestabstand=True)\n",
    "\n",
    "\n",
    "add_vergleich('TST, EAN, LC, BNR, MIT, RHTI',\n",
    "              ['TRÄGER', 'SEITE', 'TAKE', 'EAN/PEAN', 'LC', 'BNR', 'MIT', 'RHTI'])\n",
    "\n",
    "add_vergleich('TST, EAN, RHTI, T-RHTI',\n",
    "              ['TRÄGER', 'SEITE', 'TAKE', 'EAN/PEAN', 'T-RHTI', 'RHTI'])\n",
    "\n",
    "add_vergleich('TST, EAN, LC, BNR, RHTI',\n",
    "              ['TRÄGER', 'SEITE', 'TAKE', 'EAN/PEAN', 'LC', 'BNR', 'RHTI'])\n",
    "\n",
    "add_vergleich('TST, EAN, RHTI',\n",
    "              ['TRÄGER', 'SEITE', 'TAKE', 'EAN/PEAN', 'RHTI'])\n",
    "\n",
    "\n",
    "add_vergleich('EAN, LC, BNR, RHTI',\n",
    "              ['EAN/PEAN', 'LC', 'BNR', 'RHTI'],\n",
    "              traeger_seite_take_fehlen=True)\n",
    "\n",
    "add_vergleich('EAN, LC, BNR',\n",
    "              ['EAN/PEAN', 'LC', 'BNR'],\n",
    "              traeger_seite_take_fehlen=True)\n",
    "\n",
    "\n",
    "add_vergleich('TST, LC, BNR, T-RHTI',\n",
    "              ['TRÄGER', 'SEITE', 'TAKE', 'LC', 'BNR', 'T-RHTI'],\n",
    "             schliesse_dubletten_auch_ein_wenn_nicht_mindestabstand=True)\n",
    "\n",
    "add_vergleich('LC, BNR, T-RHTI',\n",
    "              ['LC', 'BNR', 'T-RHTI'],\n",
    "             traeger_seite_take_fehlen=True)\n",
    "\n",
    "add_vergleich('LC, BNR, RHTI',\n",
    "              ['LC', 'BNR', 'RHTI'],\n",
    "              traeger_seite_take_fehlen=True)\n",
    "\n",
    "add_vergleich('TST, LC, BNR, RHTI',\n",
    "              ['TRÄGER', 'SEITE', 'TAKE', 'LC', 'BNR', 'RHTI'],\n",
    "              bnr_mindestlaenge=True)\n",
    "\n",
    "add_vergleich('TST, MIT, RHTI',\n",
    "              ['TRÄGER', 'SEITE', 'TAKE', 'MIT', 'RHTI'])\n",
    "\n",
    "add_vergleich('RHTI, T-RHTI' ,\n",
    "              ['RHTI', 'T-RHTI'],\n",
    "              traeger_seite_take_fehlen=True,\n",
    "              bnr_fehlt=True)\n",
    "\n",
    "\n",
    "add_vergleich('LC, MIT, RHTI',\n",
    "              ['LC', 'MIT', 'RHTI', 'DAUER'],\n",
    "              traeger_seite_take_fehlen=True,\n",
    "              bnr_fehlt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38036419",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\" Vergleichen \"\"\"\n",
    "print('Bereite Vergleich vor')\n",
    "\n",
    "# Konfiguration: Vergleich\n",
    "\n",
    "PATTERN_NON_ALPHANUMERIC = re.compile(r'\\W+')\n",
    "MINIMALER_ABSTAND_DUBLETTE_ORIGINAL = 80\n",
    "abstand_erfuellt_spalten_name = f'Abstand >= {MINIMALER_ABSTAND_DUBLETTE_ORIGINAL}?'\n",
    "\n",
    "kb['hat Dubletten?'] = False\n",
    "kb['ist Dublette?'] = False\n",
    "kb[abstand_erfuellt_spalten_name] = False\n",
    "kb['Original ANR'] = np.nan\n",
    "kb['Original BEST'] = np.nan\n",
    "kb['Original RHTI'] = np.nan\n",
    "kb['Fundmethode'] = np.nan\n",
    "kb['Abstand'] = np.nan\n",
    "kb['Abstand'] = kb['Abstand'].astype('Int64')\n",
    "kb['t_ANR'] = kb.index\n",
    "\n",
    "gefunden = dict()\n",
    "gefunden['total'] = dict()\n",
    "ignoriert = 'ignorierte Dubletten (mit weniger Kriterien anderes Original gefunden, zur Sicherheit verworfen (Ergebnisse ohne Abstandsprüfung!)'\n",
    "gefunden[ignoriert] = 0\n",
    "gefunden['total']['insgesamt'] = 0\n",
    "gefunden['total'][abstand_erfuellt_spalten_name] = 0\n",
    "gefunden['total']['als Dubletten markiert'] = 0\n",
    "\n",
    "print('Normalisiere Daten')\n",
    "# Alle Spalten mit Strings normalisieren\n",
    "normalisiert_kb = kb.copy()\n",
    "string_spalten = normalisiert_kb.select_dtypes(include=['string'])\n",
    "normalisiert_kb.loc[:, string_spalten.columns] = string_spalten.apply(lambda x: x.str.lower().str.replace(PATTERN_NON_ALPHANUMERIC, ''))\n",
    "normalisiert_kb.loc[:, string_spalten.columns].replace('', np.nan, inplace=True)\n",
    "\n",
    "\n",
    "for reihenfolge, methode in enumerate(vergleiche, 1):\n",
    "    fundmethode = f'{reihenfolge}: {methode}'\n",
    "    nutze_spalten = vergleiche[methode]['nutze_spalten']\n",
    "\n",
    "    print(f'\\nVergleiche: {fundmethode} ({reihenfolge}/{len(vergleiche)})')\n",
    "    print(f'Spalten: {nutze_spalten}')\n",
    "    print(f\"Bedingungen: {[vgl for vgl in vergleiche[methode].keys() if 'nutze_spalten' not in vgl]}\")\n",
    "    \n",
    "    \n",
    "    normalisiert = False\n",
    "    if vergleiche[methode].get('normalisiere', True):\n",
    "        normalisiert = True\n",
    "        vgl = normalisiert_kb[(kb['ist Dublette?'] == False)].dropna(subset=nutze_spalten).copy()\n",
    "    else:\n",
    "        vgl = kb[(kb['ist Dublette?'] == False)].dropna(subset=nutze_spalten).copy()\n",
    "        \n",
    "    if vergleiche[methode].get('bnr_mindestlaenge', False):\n",
    "        bnr_mindestlaenge = 4\n",
    "        if normalisiert:\n",
    "            # '[]' abziehen\n",
    "            bnr_mindestlaenge -= 2\n",
    "        vgl.drop( (vgl[ ~(vgl['BNR'].str.len() >= bnr_mindestlaenge) ] ).index, inplace=True)\n",
    "    \n",
    "    if vergleiche[methode].get('traeger_seite_take_fehlen', False):\n",
    "        tst_spalten = ['TRÄGER', 'SEITE', 'TAKE']\n",
    "        vgl.drop( (vgl[ ~(vgl[tst_spalten].isnull().all('columns')) ] ).index, inplace=True)\n",
    "    \n",
    "    \n",
    "    if vergleiche[methode].get('bnr_fehlt', False):\n",
    "        vgl.drop( (vgl[ ~(vgl['BNR'].isnull()) ] ).index, inplace=True)\n",
    "    \n",
    "    vgl.dropna(subset=nutze_spalten, inplace=True)\n",
    "    vgl.sort_values(['BEST'], inplace=True)\n",
    "    \n",
    "    dubletten = vgl.duplicated(subset=nutze_spalten)\n",
    "    originale = vgl.groupby(nutze_spalten)['t_ANR'].transform('first').values\n",
    "    \n",
    "    vgl['ist Dublette?'] = dubletten\n",
    "    vgl['Original ANR'] = originale\n",
    "    \n",
    "    if len(vgl[vgl['ist Dublette?'] == True]) > 0:\n",
    "        # Schon als Originale registrierte Einheiten nicht als Dubletten zählen\n",
    "        gefunden[ignoriert] += vgl.loc[(vgl['ist Dublette?'] == True) & (kb['hat Dubletten?'] == True), 'ist Dublette?'].sum() \n",
    "        vgl.loc[ (vgl['ist Dublette?'] == True) & (kb['hat Dubletten?'] == True), 'ist Dublette?'] = False\n",
    "\n",
    "\n",
    "        vgl['Original ANR'] = vgl['Original ANR']\n",
    "        vgl['Original BEST'] = kb.loc[vgl['Original ANR'], 'BEST'].values\n",
    "        vgl['Original RHTI'] = kb.loc[vgl['Original ANR'], 'RHTI'].values\n",
    "\n",
    "        vgl.drop( vgl[(vgl['ist Dublette?'] == False)].index, inplace=True)\n",
    "        \n",
    "        vgl['eigene ANR (numerisch)'] = pd.to_numeric(vgl.index.str.replace(r'[^\\d]', '', regex=True))\n",
    "        vgl['originale ANR (numerisch)'] = pd.to_numeric(vgl['Original ANR'].str.replace(r'[^\\d]', '', regex=True))\n",
    "        vgl['Abstand'] = abs(vgl['eigene ANR (numerisch)'] - vgl['originale ANR (numerisch)'])\n",
    "\n",
    "        # Ergebnisse übertragen\n",
    "        if vergleiche[methode].get('schliesse_dubletten_auch_ein_wenn_nicht_mindestabstand', False):\n",
    "             kb.loc[vgl.index, 'ist Dublette?'] = True\n",
    "        else:\n",
    "            kb.loc[vgl.index, 'ist Dublette?'] = vgl['Abstand'] >= MINIMALER_ABSTAND_DUBLETTE_ORIGINAL\n",
    "\n",
    "\n",
    "        kb.loc[vgl.index, 'Original ANR'] = vgl['Original ANR']\n",
    "        kb.loc[vgl.index, 'Original BEST'] = vgl['Original BEST']\n",
    "        kb.loc[vgl.index, 'Original RHTI'] = vgl['Original RHTI']\n",
    "        kb.loc[kb.index.isin(vgl['Original ANR']), 'hat Dubletten?'] = True\n",
    "        kb.loc[vgl.index, 'Fundmethode'] = fundmethode\n",
    "        kb.loc[vgl.index, 'Abstand'] = vgl['Abstand']\n",
    "        kb.loc[vgl.index, abstand_erfuellt_spalten_name] =  vgl['Abstand'] >= MINIMALER_ABSTAND_DUBLETTE_ORIGINAL\n",
    "    \n",
    "    \n",
    "    gefunden_insgesamt = 0\n",
    "    gefunden_markiert = 0\n",
    "    gefunden_abzgl_zu_nah = 0\n",
    "    if len(vgl[vgl['ist Dublette?'] == True]) > 0:\n",
    "        gefunden_insgesamt = len(vgl['ist Dublette?'])\n",
    "        gefunden_markiert = (kb.loc[vgl.index, 'ist Dublette?']).sum()\n",
    "        gefunden_abzgl_zu_nah = len(vgl[(vgl['ist Dublette?'] == True) & (vgl['Abstand'] >= MINIMALER_ABSTAND_DUBLETTE_ORIGINAL)])\n",
    "    \n",
    "    print(f'Gefunden (insgesamt): {gefunden_insgesamt}')\n",
    "    print(f'Gefunden (ohne zu nahe ANR): {gefunden_abzgl_zu_nah}')\n",
    "    print(f'Gefunden (als Dubletten markiert): {gefunden_markiert}\\n')\n",
    "    \n",
    "    gefunden[fundmethode] = dict()\n",
    "    gefunden[fundmethode]['insgesamt'] = gefunden_insgesamt\n",
    "    gefunden[fundmethode]['als Dubletten markiert'] = gefunden_markiert\n",
    "    gefunden[fundmethode][abstand_erfuellt_spalten_name] = gefunden_abzgl_zu_nah\n",
    "    gefunden['total']['insgesamt'] += gefunden[fundmethode]['insgesamt']\n",
    "    gefunden['total']['als Dubletten markiert'] += gefunden[fundmethode]['als Dubletten markiert']\n",
    "    gefunden['total'][abstand_erfuellt_spalten_name] += gefunden[fundmethode][abstand_erfuellt_spalten_name]\n",
    "    \n",
    "    del vgl \n",
    "\n",
    "del kb['t_ANR']\n",
    "\n",
    "assert len(kb[ (kb['ist Dublette?'] == True) & (kb.index.isin(kb['Original ANR'])) ]) == 0\n",
    "assert len(kb[ (kb['ist Dublette?'] == True) & (kb['hat Dubletten?'] == True) ]) == 0\n",
    "           \n",
    "ipd.display(gefunden['total'])\n",
    "print('Fertig!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1787fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = dict()\n",
    "prev = None\n",
    "for standort in standorte_nach_prioritaet:\n",
    "    if standort in standort_listen:\n",
    "        r[f'{standort}: dubletten in {standort}'] = len(kb[(kb['BEST'] == standort) & (kb['ist Dublette?'] == True)])\n",
    "        r[f'{standort}: dubletten in {standort} mit original in {standort}'] = len(kb[(kb['BEST'] == standort) & (kb['ist Dublette?'] == True) & (kb['Original BEST'] == standort)])\n",
    "        if prev is not None:\n",
    "            r[f'{standort}: dubletten in {standort} mit original in {prev}'] = len(kb[(kb['BEST'] == standort) & (kb['ist Dublette?'] == True) & (kb['Original BEST'] == prev)])\n",
    "        prev = standort\n",
    "    \n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14fb836",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gefunden.copy()\n",
    "\n",
    "del g['total']\n",
    "del g[ignoriert]\n",
    "\n",
    "for m in g:\n",
    "    i = g[m]['insgesamt']\n",
    "    a = g[m][abstand_erfuellt_spalten_name]\n",
    "    print(f'{i},{a}')\n",
    "\n",
    "print('\\n')\n",
    "for m in g:\n",
    "    i = g[m]['insgesamt']\n",
    "    a = g[m][abstand_erfuellt_spalten_name]\n",
    "    print(f'{m}: {i},{a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a19bde7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = kb[(kb['Fundmethode'].str.contains('5') == True) & (kb['RHTI'].str.contains('Vol.') == True) & (kb['Fundmethode'].str.contains('15') == False) & (kb['ist Dublette?'] == True)].sample(10)\n",
    "\n",
    "x.sort_values('Original ANR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fc2aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = kb[kb.index.isin(x['Original ANR'])].sort_values('Original ANR')\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7735d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = kb.loc[kb['ist Dublette?'] == True, 'Fundmethode'].value_counts()\n",
    "y =  x.index\n",
    "ax = sns.barplot(x=x, y=y)\n",
    "ax.set(ylabel='Reihenfolge: Vergleichsmethode', xlabel='Dubletten (abs.)')\n",
    "plt.title('Fundmethoden nach Fundmenge')\n",
    "plt.savefig(f'{save_pfad}/img/fundmethoden.svg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "x = kb.loc[(kb['ist Dublette?'] == True), ['BEST', 'Original BEST']].value_counts().unstack().sort_values('BEST')\n",
    "ax = x.plot(kind='bar')\n",
    "plt.title('Wo stehen die Originale der Dubletten?')\n",
    "ax.legend(title='Standort des Originals')\n",
    "ax.set(ylabel='Originale', xlabel='Standort der Dublette')\n",
    "plt.savefig(f'{save_pfad}/img/dubletten_originale.svg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "    \n",
    "x = kb.loc[:, ['BEST', 'ist Dublette?']].value_counts()\n",
    "ax = x.unstack(level=1).plot(kind='bar', stacked=True)\n",
    "ax.legend(['Original', 'Dublette'])\n",
    "plt.title('Dubletten nach Standort (bezogen auf die jeweilige Gesamtmenge)')\n",
    "ax.set(ylabel='Einheiten', xlabel='Standort')\n",
    "plt.savefig(f'{save_pfad}/img/dubletten_nach_standort.svg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "for standort in standorte_nach_prioritaet: \n",
    "    if standort in standort_listen:\n",
    "        x = kb.loc[kb['BEST'] == standort, ['BEST', 'ist Dublette?']].value_counts(normalize=True) * 100\n",
    "        ax = x.unstack().plot(kind='bar', stacked=True)\n",
    "        ax.legend(['Original', 'Dublette'])\n",
    "        plt.title(f'{standort}: Dubletten im Bestand (prozentual)')\n",
    "        ax.set(ylabel='Einheiten (%)', xlabel=None)\n",
    "        plt.savefig(f'{save_pfad}/img/{standort}_dubletten_nach_standort.svg', bbox_inches='tight')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c5a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_file = Path(f'{save_pfad}/ergebnis.xlsx')\n",
    "if results_file.exists():\n",
    "    results_file.unlink()\n",
    "\n",
    "out = kb.copy()\n",
    "bool_cols = list()\n",
    "for col, col_type in dict(out.dtypes).items():\n",
    "    if col_type == 'bool':\n",
    "        out[col] = out[col].astype('object')\n",
    "        out.loc[(out[col] == True), col] = 'x'\n",
    "        out.loc[(out[col] == False), col] = np.nan\n",
    "\n",
    "        \n",
    "with pd.ExcelWriter(results_file) as writer:\n",
    "    for standort in standorte_nach_prioritaet:\n",
    "        if standort in standort_listen:\n",
    "            out.to_excel(writer, sheet_name='Alles')\n",
    "            out.loc[out['BEST'] == standort, :].to_excel(writer, sheet_name=f'{standort} Alles')\n",
    "            out.loc[out['BEST'] == standort, :].sample(500).to_excel(writer, sheet_name=f'{standort} Alles (500)')\n",
    "            out.loc[(out['BEST'] == standort) & (out['ist Dublette?'] == 'x'), :].to_excel(writer, sheet_name=f'{standort} Dubletten')\n",
    "\n",
    "del out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f184ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda (base2)",
   "language": "python",
   "name": "anaconda-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
